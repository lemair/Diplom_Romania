{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train.isnull().sum().sort_values(ascending =False).head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum().sort_values(ascending =False).head(20)/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu','LotFrontage','GarageCond','GarageType','GarageYrBlt','GarageQual','BsmtExposure','BsmtFinType2','BsmtFinType1','BsmtCond','BsmtQual'],axis=1,inplace=True)\n",
    "df_test.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu','LotFrontage','GarageCond','GarageType','GarageYrBlt','GarageQual','BsmtExposure','BsmtFinType2','BsmtFinType1','BsmtCond','BsmtQual'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "missing_values = df_train.columns[df_train.isna().any()].to_list()\n",
    "for each in missing_values:\n",
    "    if (df_train[each].dtypes =='float64'):\n",
    "        minimum= int(df_train[each].quantile(0.25))\n",
    "        maximum= int(df_train[each].quantile(0.75))\n",
    "        A=df_train[df_train[each].isnull()].index.tolist()\n",
    "        for i in A:\n",
    "            df_train.loc[i,each]=random.randint(minimum,maximum)\n",
    "        df_train[each]=pd.to_numeric(df_train[each])\n",
    "   \n",
    "\n",
    "    elif(df_train[each].dtypes == 'object'):\n",
    "        if ('True' in str(df_train[each].str.contains('No').unique().tolist())):\n",
    "            df_train[each].fillna('No',inplace=True)\n",
    "        elif('True' in str(df_train[each].str.contains('None').unique().tolist())):\n",
    "            df_train[each].fillna('None',inplace=True)\n",
    "        elif('True' in str(df_train[each].str.contains('Unf').unique().tolist())):\n",
    "            df_train[each].fillna('Unf',inplace=True)\n",
    "        else:\n",
    "            A=df_train[df_train[each].isnull()].index.tolist()\n",
    "            unique = df_train[each].unique().tolist()\n",
    "            unique=pd.Series(unique).dropna().tolist()\n",
    "            for i in A:\n",
    "                df_train.loc[i,each]=random.choice(unique)\n",
    "\n",
    "\n",
    "missing_values = df_test.columns[df_test.isna().any()].to_list()\n",
    "for each in missing_values:\n",
    "    if (df_test[each].dtypes =='float64'):\n",
    "        minimum= int(df_test[each].quantile(0.25))\n",
    "        maximum= int(df_test[each].quantile(0.75))\n",
    "        A=df_test[df_test[each].isnull()].index.tolist()\n",
    "        for i in A:\n",
    "            df_test.loc[i,each]=random.randint(minimum,maximum)\n",
    "        df_test[each]=pd.to_numeric(df_test[each])\n",
    "   \n",
    "\n",
    "    elif(df_test[each].dtypes == 'object'):\n",
    "        if ('True' in str(df_test[each].str.contains('No').unique().tolist())):\n",
    "            df_test[each].fillna('No',inplace=True)\n",
    "        elif('True' in str(df_test[each].str.contains('None').unique().tolist())):\n",
    "            df_test[each].fillna('None',inplace=True)\n",
    "        elif('True' in str(df_test[each].str.contains('Unf').unique().tolist())):\n",
    "            df_test[each].fillna('Unf',inplace=True)\n",
    "        else:\n",
    "            A=df_test[df_test[each].isnull()].index.tolist()\n",
    "            unique = df_test[each].unique().tolist()\n",
    "            unique=pd.Series(unique).dropna().tolist()\n",
    "            for i in A:\n",
    "                df_test.loc[i,each]=random.choice(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['Id'],axis=1,inplace=True)\n",
    "df_test.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix train\n",
    "corrmat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix test\n",
    "corrmat = df_test.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "sns.heatmap(df_train.corr(),annot=True,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catogorical_features_ = np.array([df_train.columns[df_train.dtypes == 'object'].to_list()])\n",
    "catogorical_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the records in utilities are mostly AllPub \n",
    "df_train.drop('Utilities',axis=1,inplace=True)\n",
    "df_test.drop('Utilities',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Foundation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogorical_features_ = np.delete(catogorical_features_,np.where(catogorical_features_=='Utilities'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_match=[]\n",
    "for i,feature in enumerate(catogorical_features_): \n",
    "    test_match.append( (feature,(df_train[feature].nunique()  -  df_test[feature].nunique())))\n",
    "    if (df_train[feature].nunique()  -  df_test[feature].nunique()) != 0:\n",
    "        df_train.drop(feature,axis=1,inplace=True)\n",
    "        df_test.drop(feature,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogorical_features_ = np.array([df_train.columns[df_train.dtypes == 'object'].to_list()])\n",
    "dummies = []\n",
    "concat_dummies=[]\n",
    "for i,feature in enumerate(catogorical_features_[0]):\n",
    "    dummies.append(pd.get_dummies(df_train[feature],drop_first=True))\n",
    "    df_train = pd.concat([df_train,dummies[i]],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['MSZoning', 'Street', 'LotShape', 'LandContour','LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "               'BldgType', 'RoofStyle','MasVnrType', 'ExterQual','Foundation',  'HeatingQC', 'CentralAir',\n",
    "         'KitchenQual', 'Functional', 'GarageFinish','PavedDrive', 'SaleType', 'SaleCondition','ExterCond'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogorical_features_ = np.array([df_test.columns[df_test.dtypes == 'object'].to_list()])\n",
    "dummies = []\n",
    "concat_dummies=[]\n",
    "for i,feature in enumerate(catogorical_features_[0]):\n",
    "    dummies.append(pd.get_dummies(df_test[feature],drop_first=True))\n",
    "    df_test = pd.concat([df_test,dummies[i]],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['MSZoning', 'Street', 'LotShape', 'LandContour','LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "               'BldgType', 'RoofStyle','MasVnrType', 'ExterQual','Foundation',  'HeatingQC', 'CentralAir',\n",
    "         'KitchenQual', 'Functional', 'GarageFinish','PavedDrive', 'SaleType', 'SaleCondition','ExterCond'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df_train.drop('SalePrice',axis=1))\n",
    "y_train = np.array(df_train['SalePrice'])\n",
    "X_test = np.array(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of X_train {} \\nShape of y_test {}\\nShape of X_test {}'.format(X_train.shape,y_train.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mms.fit_transform(y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(Dense(units=512,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.add(Dense(units=256,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.add(Dense(units=256,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.add(Dense(units=128,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.add(Dense(units=1,activation='relu',kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train,y_train,epochs=100,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = regressor.history.history\n",
    "losses = np.array(pd.DataFrame(losses))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def build_classifier(optimizer,units1,units2,units3,units4):\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=units1,activation='relu',kernel_initializer='uniform'))\n",
    "    regressor.add(Dense(units=units2,activation='relu',kernel_initializer='uniform'))\n",
    "    regressor.add(Dense(units=units3,activation='relu',kernel_initializer='uniform'))\n",
    "    regressor.add(Dense(units=units4,activation='relu',kernel_initializer='uniform'))\n",
    "    regressor.add(Dense(units=1,activation='relu',kernel_initializer='uniform'))\n",
    "    regressor.compile(optimizer=optimizer,loss='mean_squared_error',metrics=['mean_squared_error'])\n",
    "    return regressor\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "regressor = KerasRegressor(build_fn=build_classifier)\n",
    "parameters = {'batch_size':[10,15,25,32],\n",
    "             'epochs':[100,300,500],\n",
    "             'optimizer':['adam','rmsprop'],\n",
    "             'units1':[512,256],\n",
    "             'units2':[256,128],\n",
    "             'units3':[256,128],\n",
    "             'units4':[256,128,64]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = regressor,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'neg_mean_squared_error',\n",
    "                           cv = 3)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(grid_search.best_score_)\n",
    "print('\\n')\n",
    "print(grid_search.best_params_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best = {'batch_size': 15, 'epochs': 500, 'optimizer': 'adam', 'units1': 512, 'units2': 128, 'units3': 128, 'units4': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(Dense(units=512,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.add(Dense(units=256,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.add(Dense(units=128,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.add(Dense(units=64,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.add(Dense(units=1,activation='relu',kernel_initializer='uniform'))\n",
    "regressor.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train,y_train,epochs=500,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = regressor.history.history\n",
    "losses = np.array(pd.DataFrame(losses))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test) \n",
    "y_pred_original = mms.inverse_transform(y_pred.reshape(-1,1))\n",
    "y_pred_original = y_pred_original.tolist()\n",
    "y_pred_original = [pred for i in y_pred_original for pred in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set =pd.read_csv('test.csv')\n",
    "submission = pd.DataFrame({'Id': test_set['Id'],'SalePrice': y_pred_original})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=pd.read_csv('submission.csv')\n",
    "df_tr=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.plot(y='SalePrice',x='Id')\n",
    "df_tr.plot(y='SalePrice',x='Id')\n",
    "##plt.scatter(X_train[:,0], y_train, color = 'red')\n",
    "##plt.plot(X_test, regressor.predict(X_test), color = 'green')\n",
    "plt.title('predicted vs actual price ')\n",
    "plt.xlabel('id')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_pred.plot(y='SalePrice',x='Id', ax=ax)\n",
    "df_tr.plot(y='SalePrice',x='Id', ax=ax)\n",
    "plt.xlabel('Id')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(['Predicted Price','Actual Price'],loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
